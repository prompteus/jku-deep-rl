{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: minigrid==2.2.1 in /var/tmp/xkadlci2/.conda/envs/drl-imitation-learning/lib/python3.8/site-packages (2.2.1)\n",
      "Requirement already satisfied: pygame>=2.2.0 in /var/tmp/xkadlci2/.conda/envs/drl-imitation-learning/lib/python3.8/site-packages (from minigrid==2.2.1) (2.4.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /var/tmp/xkadlci2/.conda/envs/drl-imitation-learning/lib/python3.8/site-packages (from minigrid==2.2.1) (1.24.2)\n",
      "Requirement already satisfied: gymnasium>=0.26 in /var/tmp/xkadlci2/.conda/envs/drl-imitation-learning/lib/python3.8/site-packages (from minigrid==2.2.1) (0.27.1)\n",
      "Requirement already satisfied: gymnasium-notices>=0.0.1 in /var/tmp/xkadlci2/.conda/envs/drl-imitation-learning/lib/python3.8/site-packages (from gymnasium>=0.26->minigrid==2.2.1) (0.0.1)\n",
      "Requirement already satisfied: jax-jumpy>=0.2.0 in /var/tmp/xkadlci2/.conda/envs/drl-imitation-learning/lib/python3.8/site-packages (from gymnasium>=0.26->minigrid==2.2.1) (1.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /var/tmp/xkadlci2/.conda/envs/drl-imitation-learning/lib/python3.8/site-packages (from gymnasium>=0.26->minigrid==2.2.1) (6.3.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /var/tmp/xkadlci2/.conda/envs/drl-imitation-learning/lib/python3.8/site-packages (from gymnasium>=0.26->minigrid==2.2.1) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /var/tmp/xkadlci2/.conda/envs/drl-imitation-learning/lib/python3.8/site-packages (from gymnasium>=0.26->minigrid==2.2.1) (4.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /var/tmp/xkadlci2/.conda/envs/drl-imitation-learning/lib/python3.8/site-packages (from importlib-metadata>=4.8.0->gymnasium>=0.26->minigrid==2.2.1) (3.15.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install minigrid==2.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "import random\n",
    "from typing import NamedTuple, Any, Iterable, Callable\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import minigrid\n",
    "import gymnasium as gym\n",
    "import lovely_tensors\n",
    "import lovely_numpy\n",
    "import lightning\n",
    "\n",
    "def lovely(x):\n",
    "    \"summarizes important tensor properties\"\n",
    "    if isinstance(x, np.ndarray):\n",
    "        return lovely_numpy.lovely(x)\n",
    "    return lovely_tensors.lovely(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transition(NamedTuple):\n",
    "    state: torch.Tensor\n",
    "    action: torch.Tensor\n",
    "    reward: torch.Tensor\n",
    "    next_state: torch.Tensor\n",
    "    done: torch.Tensor\n",
    "\n",
    "\n",
    "class ReplayBuffer(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, capacity: int, seed = None):\n",
    "        self.capacity = capacity\n",
    "        self.buffer: list[Transition] = []\n",
    "        self.seed = seed\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "    \n",
    "    def __next__(self):\n",
    "        return self.rng.choice(self.buffer)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def add(self, t: Transition):\n",
    "        self.buffer.append(t)\n",
    "        if len(self.buffer) > self.capacity:\n",
    "            self.buffer.pop(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minigrid Environment\n",
    "from minigrid.wrappers import ImgObsWrapper\n",
    "\n",
    "class ChannelFirst(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        old_shape = env.observation_space.shape\n",
    "        self.observation_space = {}\n",
    "        self.observation_space = gym.spaces.Box(0, 255, shape=(3, 7, 7))\n",
    "\n",
    "    def observation(self, observation):\n",
    "        return np.swapaxes(observation, 2, 0)\n",
    "\n",
    "class ScaledFloatFrame(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        gym.ObservationWrapper.__init__(self, env)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        # careful! This undoes the memory optimization, use\n",
    "        # with smaller replay buffers only.\n",
    "        return np.array(observation).astype(np.float32)\n",
    "\n",
    "class MinigridEmpty5x5ImgObs(gym.Wrapper):\n",
    "    \"\"\"Minigrid with image observations provided by minigrid, partially observable.\"\"\"\n",
    "    def __init__(self):\n",
    "        env = gym.make('MiniGrid-Empty-5x5-v0')\n",
    "        env = ScaledFloatFrame(ChannelFirst(ImgObsWrapper(env)))\n",
    "        super().__init__(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import itertools\n",
    "\n",
    "import torchvision\n",
    "\n",
    "\n",
    "class MlpQNet(torch.nn.Module):\n",
    "    def __init__(self, num_actions: int):\n",
    "        super().__init__()\n",
    "        self.num_actions = num_actions\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Flatten(), \n",
    "            torch.nn.Linear(3*7**2, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, num_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        if isinstance(x, np.ndarray):\n",
    "            param = next(self.parameters())\n",
    "            x = torch.tensor(x).to(param)\n",
    "\n",
    "        if len(x.shape) == 3:\n",
    "            x = x.unsqueeze(dim=0)\n",
    "\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "def set_submodule(module: torch.nn.Module, submodule_path: str, submodule: torch.nn.Module) -> None:\n",
    "    *parent_path, attr_name = submodule_path.split(\".\")\n",
    "    parent = module\n",
    "    for child in parent_path:\n",
    "        parent = getattr(parent, child)\n",
    "    setattr(parent, attr_name, submodule)\n",
    "\n",
    "\n",
    "# Copied from my previous homework\n",
    "class VisionQNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Policy network is compatible with any CNN architecture as long as:\n",
    "    1) One of the conv layers determines how many channels it can process\n",
    "    2) One of the linear layers determines the number of output neurons\n",
    "    \n",
    "    This should be enough to support all standard architectures\n",
    "\n",
    "    >>> policy_nn = PolicyNetwork(\n",
    "    ...     actions=5,\n",
    "    ...     architecture=\"efficientnet_b0\",\n",
    "    ...     input_conv=\"features.0.0\",\n",
    "    ...     output_lin=\"classifier.1\",\n",
    "    ...     pretrained_weights=None, # \"IMAGENET1K_V1\"\n",
    "    ... )\n",
    "    >>> inputs = torch.rand(size=(16, 1, 64, 64))\n",
    "    >>> policy_nn(inputs).shape\n",
    "    torch.Size([16, 5])\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        actions: int | dict[int, str],\n",
    "        architecture: str,\n",
    "        input_conv: str,\n",
    "        output_lin: str,\n",
    "        pretrained_weights = None,\n",
    "        seed: int = 42,\n",
    "    ) -> None:\n",
    "        super(VisionQNet, self).__init__()\n",
    "        if isinstance(actions, int):\n",
    "            self.n_units_out = actions\n",
    "            self.actions = {i: f\"action_{i}\" for i in range(actions)}\n",
    "        else:\n",
    "            self.n_units_out = len(actions)\n",
    "            self.actions = actions\n",
    "        self.architecture = architecture\n",
    "        self.input_conv = input_conv\n",
    "        self.output_lin = output_lin\n",
    "        self.nn = torchvision.models.get_model(self.architecture)\n",
    "        self._patch_input_shape()\n",
    "        self._patch_output_shape()\n",
    "        self.init(pretrained_weights, seed)\n",
    "\n",
    "    def init(self, pretrained_weights = None, seed: int = None) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the model parameters, either randomly or with pretrained weights.\n",
    "        Patches the architecture to have desired input and output shape.\n",
    "        \"\"\"\n",
    "        if seed is not None:\n",
    "            torch.random.manual_seed(seed)\n",
    "\n",
    "        state_dict = torchvision.models.get_model(self.architecture, weights=pretrained_weights).state_dict()\n",
    "\n",
    "        for key in list(state_dict.keys()):\n",
    "            if key.startswith(self.input_conv) or key.startswith(self.output_lin):\n",
    "                state_dict.pop(key)\n",
    "\n",
    "        incompatible = self.nn.load_state_dict(state_dict, strict=False)\n",
    "        if len(incompatible.unexpected_keys) != 0:\n",
    "            raise ValueError(f\"Unexpected additional keys in pretrained weights: {incompatible.unexpected_keys}\")\n",
    "        \n",
    "        for key in incompatible.missing_keys:\n",
    "            assert isinstance(key, str)\n",
    "            if key.startswith(self.input_conv) or key.startswith(self.output_lin):\n",
    "                continue\n",
    "            raise ValueError(f\"Unexpected missing key in pretrained weights: {key}\")\n",
    "\n",
    "        del state_dict\n",
    "\n",
    "        in_out_params = itertools.chain(\n",
    "            self.nn.get_submodule(self.input_conv).parameters(),\n",
    "            self.nn.get_submodule(self.output_lin).parameters(),\n",
    "        )\n",
    "\n",
    "        for param in in_out_params:\n",
    "            torch.nn.init.trunc_normal_(param, mean=0, std=1e-4, a=-0.01, b=0.01)            \n",
    "\n",
    "    def _patch_input_shape(self) -> None:\n",
    "        \"\"\"\n",
    "        Make the architecture accept a single (grayscale) channel\n",
    "        \"\"\"\n",
    "        old_in_conv = self.nn.get_submodule(self.input_conv)\n",
    "        assert isinstance(old_in_conv, torch.nn.Conv2d)\n",
    "\n",
    "        if old_in_conv.in_channels == 1:\n",
    "            return\n",
    "\n",
    "        new_in_conv = torch.nn.Conv2d(\n",
    "            in_channels = 1, \n",
    "            out_channels = old_in_conv.out_channels,\n",
    "            kernel_size = old_in_conv.kernel_size,\n",
    "            stride = old_in_conv.stride,\n",
    "            padding = old_in_conv.padding,\n",
    "            bias = old_in_conv.bias is not None,\n",
    "        ).to(\n",
    "            old_in_conv.weight\n",
    "        )\n",
    "        set_submodule(self.nn, self.input_conv, new_in_conv)\n",
    "\n",
    "    def _patch_output_shape(self) -> None:\n",
    "        \"\"\"\n",
    "        Make the architecture output the correct shape\n",
    "        \"\"\"\n",
    "        old_out_lin = self.nn.get_submodule(self.output_lin)\n",
    "        assert isinstance(old_out_lin, torch.nn.Linear)\n",
    "        \n",
    "        if old_out_lin.out_features == self.n_units_out:\n",
    "            return\n",
    "\n",
    "        new_out_lin = torch.nn.Linear(\n",
    "            in_features = old_out_lin.in_features,\n",
    "            out_features = self.n_units_out,\n",
    "            bias = old_out_lin.bias is not None,\n",
    "        ).to(\n",
    "            old_out_lin.weight\n",
    "        )\n",
    "        set_submodule(self.nn, self.output_lin, new_out_lin)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # select only last channel if there are more\n",
    "        # TODO revisit this. it's coming from previous homework and maybe not relevant anymore\n",
    "        x = x[:, (-1,), :, :]\n",
    "        return self.nn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "VisionQNet(5, \"mobilenet_v3_small\", \"features.0.0\", \"classifier.3\")\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs: array[3, 7, 7] f32 n=147 x∈[0., 8.000] μ=2.020 σ=2.075\n",
      "info: {}\n",
      "action_space: Discrete(7)\n"
     ]
    }
   ],
   "source": [
    "envs = MinigridEmpty5x5ImgObs()\n",
    "state, info = envs.reset()\n",
    "print(\"obs:\", lovely(state))\n",
    "print(\"info:\", info)\n",
    "print(\"action_space:\", envs.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def set_seed(env, seed=None):\n",
    "#     if seed is None:\n",
    "#         return \n",
    "    \n",
    "#     random.seed(seed)\n",
    "#     env.seed(seed)\n",
    "#     np.random.seed(seed)\n",
    "#     torch.manual_seed(seed)\n",
    "#     if torch.cuda.is_available():\n",
    "#         torch.cuda.manual_seed(seed)\n",
    "#         torch.cuda.manual_seed_all(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(abc.ABC):\n",
    "    def select_action(self, state) -> int:\n",
    "        ...\n",
    "\n",
    "class DQN(lightning.LightningModule, Agent):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_config: dict[str, Any],\n",
    "        num_actions: int,\n",
    "        use_double_dqn: bool,\n",
    "        optimizer_class: str,\n",
    "        use_pretrained_weights: str | None = None,\n",
    "        optimizer_config: dict[str, Any] = None,\n",
    "        epsilon: float = 0.1,\n",
    "        tau: float = 1e-3,\n",
    "        gamma: float = 0.99,\n",
    "        use_vision: bool = True,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=[\"use_pretrained_weights\"])\n",
    "        self.model_config = model_config\n",
    "\n",
    "        if optimizer_config is None:\n",
    "            optimizer_config = {}\n",
    "        self.optimizer_config = optimizer_config\n",
    "        self.optimizer_class = optimizer_class\n",
    "        \n",
    "        # TODO does it matter that they are initialized with the same weights?\n",
    "        if use_vision:\n",
    "            self.qnn = VisionQNet(**model_config, pretrained_weights=use_pretrained_weights)\n",
    "            self.qnn_target = VisionQNet(**model_config, pretrained_weights=use_pretrained_weights)\n",
    "        else:\n",
    "            self.qnn = MlpQNet(**model_config)\n",
    "            self.qnn_target = MlpQNet(**model_config)\n",
    "        \n",
    "        self.loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "        self.num_actions = num_actions\n",
    "        self.use_double_dqn = use_double_dqn\n",
    "        self.epsilon = epsilon\n",
    "        self.tau = tau\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.qnn(x)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def select_action(self, observation: torch.Tensor, greedy: bool) -> int:\n",
    "        if greedy or random.random() > self.epsilon:\n",
    "            q_values = self.qnn(observation) \n",
    "            return torch.argmax(q_values).item()\n",
    "        return random.randrange(self.num_actions)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer_class = getattr(torch.optim, self.optimizer_class)\n",
    "        return optimizer_class(self.qnn.parameters(), **self.optimizer_config)\n",
    "\n",
    "    def training_step(self, batch: Transition, batch_idx):\n",
    "        with torch.no_grad():\n",
    "            if self.use_double_dqn:\n",
    "                next_q_values = self.select_action(batch.next_state, greedy=True)\n",
    "                next_value_estimate = self.qnn_target(batch.next_state, next_q_values)\n",
    "            else:\n",
    "                next_value_estimate = torch.max(self.qnn_target(batch.next_state), dim=1).values\n",
    "            td_target = batch.reward + self.gamma * next_value_estimate * (1 - batch.done)\n",
    "        \n",
    "        td_error: torch.Tensor\n",
    "        td_error = self.loss_fn(self.qnn(batch), td_target)\n",
    "        self.log(\"td_error\", td_error)\n",
    "        return td_error\n",
    "    \n",
    "    def on_train_batch_end(self, outputs, batch, batch_idx) -> None:\n",
    "        self.soft_update_target_nn()\n",
    "        # TODO decay epsilon\n",
    "        # self.epsilon = max(self.epsilon_lb, self.epsilon_ub - self.global_step / self.epsilon_decay)\n",
    "        return super().on_train_batch_end(outputs, batch, batch_idx)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def soft_update_target_nn(self):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = tau * θ_local + (1 - tau) * θ_target\n",
    "        \"\"\"\n",
    "        params = zip(self.qnn_target.parameters(), self.qnn.parameters())\n",
    "        for target_param, param in params:\n",
    "            target_param.copy_(self.tau * param + (1.0 - self.tau) * target_param)\n",
    "\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # TODO\n",
    "        ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelExperienceGenerator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        agent: Agent,\n",
    "        make_env: Callable[[int | None, bool], gym.Env],\n",
    "        make_env_kwargs: dict[str, Any],\n",
    "        num_parallel_envs: int,\n",
    "    ) -> None:\n",
    "        self.agent = agent\n",
    "        self.make_env = make_env\n",
    "        self.num_parallel_envs = num_parallel_envs\n",
    "\n",
    "        self.envs = gym.vector.AsyncVectorEnv([\n",
    "            lambda: make_env(**make_env_kwargs)\n",
    "            for _ in range(num_parallel_envs)\n",
    "        ])\n",
    "\n",
    "    def __iter__(self) -> Iterable[Transition]:\n",
    "        states, _ = self.envs.reset()\n",
    "        while True:\n",
    "            actions = self.agent.select_action(states)\n",
    "            next_states, rewards, dones, _ = envs.step(actions)\n",
    "            for s, a, r, s_, d in zip(states, actions, next_states, rewards, dones):\n",
    "                yield Transition(s, a, r, s_, d)\n",
    "            states = next_states\n",
    "\n",
    "\n",
    "class ExperienceCollectionCallback(lightning.Callback):\n",
    "    def __init__(\n",
    "        self,\n",
    "        parallel_experience_generator: ParallelExperienceGenerator,\n",
    "        buffer: ReplayBuffer,\n",
    "        collect_every_n_steps: int,\n",
    "        collect_num_steps_in_each_env: int,\n",
    "        num_parallel_envs: int,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.parallel_experience_collector = parallel_experience_generator\n",
    "        self.buffer = buffer\n",
    "        self.collect_every_n_steps = collect_every_n_steps\n",
    "        self.collect_num_steps_in_each_env = collect_num_steps_in_each_env\n",
    "        self.num_parallel_envs = num_parallel_envs\n",
    "\n",
    "    def on_train_start(self, trainer, pl_module) -> None:\n",
    "        self.collect_experience()\n",
    "\n",
    "    def on_train_batch_end(self, trainer: lightning.Trainer, pl_module, outputs, batch, batch_idx, dataloader_idx) -> None:\n",
    "        if trainer.global_step % self.collect_every_n_steps == 0:\n",
    "            self.collect_experience()\n",
    "\n",
    "    def collect_experience(self):\n",
    "        for step in range(self.collect_num_steps_in_each_env):\n",
    "            transitions = next(self.parallel_experience_collector)\n",
    "            for transition in transitions:\n",
    "                self.buffer.add(transition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_actions = 5\n",
    "\n",
    "mobilenet_v3_small_config = {\n",
    "    \"actions\": num_actions,\n",
    "    \"architecture\": \"mobilenet_v3_small\",\n",
    "    \"input_conv\": \"features.0.0\",\n",
    "    \"output_lin\": \"classifier.3\",\n",
    "}\n",
    "\n",
    "efficientnet_b0_config = {\n",
    "    \"actions\": num_actions,\n",
    "    \"architecture\": \"efficientnet_b0\",\n",
    "    \"input_conv\": \"features.0.0\",\n",
    "    \"output_lin\": \"classifier.1\",\n",
    "}\n",
    "\n",
    "mlp_config = {\n",
    "    \"num_actions\": num_actions,\n",
    "}\n",
    "\n",
    "dqn = DQN(\n",
    "    model_config = mlp_config,\n",
    "    use_vision = False,\n",
    "    num_actions = num_actions,\n",
    "    use_double_dqn = True,\n",
    "    optimizer_class = \"AdamW\",\n",
    "    optimizer_config = dict(lr=1e-4),\n",
    "    epsilon = 0.1,\n",
    "    tau = 1e-3,\n",
    "    use_pretrained_weights=\"DEFAULT\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = ReplayBuffer(\n",
    "    capacity = 100_000,\n",
    "    seed = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_generator = ParallelExperienceGenerator(\n",
    "    agent = dqn,\n",
    "    make_env = ..., #TODO\n",
    "    make_env_kwargs = ..., #TODO\n",
    "    num_parallel_envs = 16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_collection_callback = ExperienceCollectionCallback(\n",
    "    parallel_experience_generator = experience_generator,\n",
    "    buffer = buffer,\n",
    "    collect_every_n_steps = ..., #TODO\n",
    "    collect_num_steps_in_each_env = ..., #TODO\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drl-imitation-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
