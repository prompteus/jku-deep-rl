{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRnY963jq1CW"
      },
      "source": [
        "Authors: Hofmarcher\n",
        "\n",
        "Date: 20-03-2023\n",
        "\n",
        "---\n",
        "\n",
        "This file is part of the \"Deep Reinforcement Learning\" lecture material. The following copyright statement applies to all code within this file.\n",
        "\n",
        "Copyright statement:\n",
        "This material, no matter whether in printed or electronic form, may be used for personal and non-commercial educational use only. Any reproduction of this manuscript, no matter whether as a whole or in parts, no matter whether in printed or in electronic form, requires explicit prior acceptance of the authors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eryXuKadrmRK"
      },
      "source": [
        "## Enable GPU Acceleration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e5BB3G1hXL5"
      },
      "source": [
        "---\n",
        "Before you start exploring this notebook make sure that GPU support is enabled.\n",
        "To enable the GPU backend for your notebook, go to **Edit** â†’ **Notebook Settings** and set **Hardware accelerator** to **GPU**. \n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBUs4yMsgRSz"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D64rNsQCyL6Q"
      },
      "source": [
        "Install Gymnasium and dependencies to render the environments"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install wandb 1> /dev/null\n",
        "# RELOAD KERNEL after installing wandb!"
      ],
      "metadata": {
        "id": "Tn7DcFaKPhOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqL6W_Gkgp9a"
      },
      "outputs": [],
      "source": [
        "!apt update 1> /dev/null\n",
        "\n",
        "!apt install -y \\\n",
        "  xvfb \\\n",
        "  x11-utils \\\n",
        "  python-opengl \\\n",
        "  ffmpeg \\\n",
        "  swig \\\n",
        "1> /dev/null\n",
        "\n",
        "!pip install \\\n",
        "  gymnasium==0.27.1 \\\n",
        "  gymnasium[box2d] \\\n",
        "  pyvirtualdisplay \\\n",
        "  imageio-ffmpeg \\\n",
        "  moviepy==1.0.3 \\\n",
        "  onnx==1.13.0 \\\n",
        "  onnx2pytorch==0.4.1 \\\n",
        "1> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ECmcPAOnhR4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# Auxiliary Python imports\n",
        "import os\n",
        "import math\n",
        "import io\n",
        "import base64\n",
        "import random\n",
        "import shutil\n",
        "from time import time, strftime\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "# Pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.distributions.categorical import Categorical\n",
        "import onnx\n",
        "from onnx2pytorch import ConvertModel\n",
        "\n",
        "# Environment import and set logger level to display error only\n",
        "import gymnasium as gym\n",
        "from gymnasium.spaces import Box\n",
        "from gymnasium import logger as gymlogger\n",
        "from gymnasium.wrappers import RecordVideo\n",
        "gymlogger.set_level(gym.logger.ERROR)\n",
        "\n",
        "# Plotting and notebook imports\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation\n",
        "from IPython.display import HTML, clear_output\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCKe0oEsWDMe"
      },
      "source": [
        "# Select device for training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wf0U5yqXWDMe"
      },
      "source": [
        "By default we train on GPU if one is available, otherwise we fall back to the CPU.\n",
        "If you want to always use the CPU change accordingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1npX57pWDMe"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device: \" + str(device))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! nvidia-smi"
      ],
      "metadata": {
        "id": "A1OoL6FMfgKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De3CuyBLgXos"
      },
      "source": [
        "# Setup Google Drive mount to store your results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vpd2i1MumjP0"
      },
      "outputs": [],
      "source": [
        "use_google_drive = False\n",
        "if use_google_drive:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IuPNzGVgGR0"
      },
      "source": [
        "# Download Dataset and Expert model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sy79qvPFfLRp",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Download training and validation datasets\n",
        "\n",
        "if not os.path.exists('expert.onnx'):\n",
        "    !wget --no-check-certificate 'https://cloud.ml.jku.at/s/citYJKPgmAGrHGy/download' -O expert.onnx\n",
        "\n",
        "if not os.path.exists('train.zip'):\n",
        "    !wget --no-check-certificate 'https://cloud.ml.jku.at/s/yJ2ZsfqTos3Jn9y/download' -O train.zip\n",
        "\n",
        "if not os.path.exists('val.zip'):\n",
        "    !wget --no-check-certificate 'https://cloud.ml.jku.at/s/3DxHLiqxTddepp8/download' -O val.zip\n",
        "\n",
        "# Unzip datasets\n",
        "!unzip -q -o train.zip\n",
        "!unzip -q -o val.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5chkQUwj4pT"
      },
      "source": [
        "# Auxiliary Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBSdD-22WDMf"
      },
      "source": [
        "The following cell contains classes and functions to provide some functionality for logging, plotting and exporting your model in the format required by the submission server.\n",
        "You are free to use your own logging framework if you wish (such as tensorboard or Weights & Biases).\n",
        "The logger is a very simple implementation of a CSV-file based logger.\n",
        "Additionally it creates a folder for each run with subfolders for model files, logs and videos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrjYL01ojsAD",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class Logger():\n",
        "    def __init__(self, logdir, params=None):\n",
        "        self.basepath = os.path.join(logdir, strftime(\"%Y-%m-%dT%H-%M-%S\"))\n",
        "        os.makedirs(self.basepath, exist_ok=True)\n",
        "        os.makedirs(self.log_dir, exist_ok=True)\n",
        "        if params is not None and os.path.exists(params):\n",
        "            shutil.copyfile(params, os.path.join(self.basepath, \"params.pkl\"))\n",
        "        self.log_dict = {}\n",
        "        self.dump_idx = {}\n",
        "\n",
        "    @property\n",
        "    def param_file(self):\n",
        "        return os.path.join(self.basepath, \"params.pkl\")\n",
        "\n",
        "    @property\n",
        "    def onnx_file(self):\n",
        "        return os.path.join(self.basepath, \"model.onnx\")\n",
        "\n",
        "    @property\n",
        "    def video_dir(self):\n",
        "        return os.path.join(self.basepath, \"videos\")\n",
        "    \n",
        "    @property\n",
        "    def log_dir(self):\n",
        "        return os.path.join(self.basepath, \"logs\")\n",
        "\n",
        "    def log(self, name, value):\n",
        "        if name not in self.log_dict:\n",
        "            self.log_dict[name] = []\n",
        "            self.dump_idx[name] = -1\n",
        "        self.log_dict[name].append((len(self.log_dict[name]), time(), value))\n",
        "    \n",
        "    def get_values(self, name):\n",
        "        if name in self.log_dict:\n",
        "            return [x[2] for x in self.log_dict[name]]\n",
        "        return None\n",
        "    \n",
        "    def dump(self):\n",
        "        for name, rows in self.log_dict.items():\n",
        "            with open(os.path.join(self.log_dir, name + \".log\"), \"a\") as f:\n",
        "                for i, row in enumerate(rows):\n",
        "                    if i > self.dump_idx[name]:\n",
        "                        f.write(\",\".join([str(x) for x in row]) + \"\\n\")\n",
        "                        self.dump_idx[name] = i\n",
        "\n",
        "\n",
        "def plot_metrics(logger):\n",
        "    train_loss  = logger.get_values(\"training_loss\")\n",
        "    train_entropy  = logger.get_values(\"training_entropy\")\n",
        "    val_loss = logger.get_values(\"validation_loss\")\n",
        "    val_acc = logger.get_values(\"validation_accuracy\")\n",
        "    \n",
        "    fig = plt.figure(figsize=(15,5))\n",
        "    ax1 = fig.add_subplot(131, label=\"train\")\n",
        "    ax2 = fig.add_subplot(131, label=\"val\",frame_on=False)\n",
        "    ax4 = fig.add_subplot(132, label=\"entropy\")\n",
        "    ax3 = fig.add_subplot(133, label=\"acc\")\n",
        "\n",
        "    ax1.plot(train_loss, color=\"C0\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.set_xlabel(\"Update (Training)\", color=\"C0\")        \n",
        "    ax1.xaxis.grid(False)  \n",
        "    ax1.set_ylim((0,4))\n",
        "\n",
        "    ax2.plot(val_loss, color=\"C1\")\n",
        "    ax2.xaxis.tick_top()\n",
        "    ax2.yaxis.tick_right()\n",
        "    ax2.set_xlabel('Epoch (Validation)', color=\"C1\")     \n",
        "    ax2.xaxis.set_label_position('top')     \n",
        "    ax2.xaxis.grid(False)\n",
        "    ax2.get_yaxis().set_visible(False)\n",
        "    ax2.set_ylim((0,4))\n",
        "\n",
        "    ax4.plot(train_entropy, color=\"C3\")    \n",
        "    ax4.set_xlabel('Update (Training)', color=\"black\")     \n",
        "    ax4.set_ylabel(\"Entropy\", color=\"C3\")\n",
        "    ax4.tick_params(axis='x', colors=\"black\")\n",
        "    ax4.tick_params(axis='y', colors=\"black\")\n",
        "    ax4.xaxis.grid(False)\n",
        "\n",
        "    ax3.plot(val_acc, color=\"C2\")\n",
        "    ax3.set_xlabel(\"Epoch (Validation)\", color=\"black\")\n",
        "    ax3.set_ylabel(\"Accuracy\", color=\"C2\")\n",
        "    ax3.tick_params(axis='x', colors=\"black\")\n",
        "    ax3.tick_params(axis='y', colors=\"black\")\n",
        "    ax3.xaxis.grid(False)\n",
        "    ax3.set_ylim((0,1))\n",
        "\n",
        "    fig.tight_layout(pad=2.0)\n",
        "    plt.show()\n",
        "    \n",
        "\"\"\"\n",
        "Utility functions to enable video recording of gym environment and displaying it\n",
        "\"\"\"\n",
        "def show_video_from_folder(video_dir):\n",
        "    mp4list = glob(f'{video_dir}/*.mp4')\n",
        "    if len(mp4list) > 0:\n",
        "        mp4 = mp4list[0]\n",
        "        video = io.open(mp4, 'r+b').read()\n",
        "        encoded = base64.b64encode(video)\n",
        "        display.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                    loop controls style=\"height: 400px;\">\n",
        "                    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "                 </video>'''.format(encoded.decode('ascii'))))\n",
        "    else: \n",
        "        print(\"Could not find video\")\n",
        "\n",
        "def show_video_from_file(file):\n",
        "    video = io.open(file, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    display.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "              </video>'''.format(encoded.decode('ascii'))))\n",
        "\n",
        "def save_as_onnx(torch_model, sample_input, model_path):\n",
        "    torch.onnx.export(torch_model,             # model being run\n",
        "                    sample_input,              # model input (or a tuple for multiple inputs)\n",
        "                    f=model_path,              # where to save the model (can be a file or file-like object)\n",
        "                    export_params=True,        # store the trained parameter weights inside the model file\n",
        "                    opset_version=17,          # the ONNX version to export the model to - see https://github.com/microsoft/onnxruntime/blob/master/docs/Versioning.md\n",
        "                    do_constant_folding=True,  # whether to execute constant folding for optimization\n",
        "                    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3QTC6sgj2Eq"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4xmbKPRWDMg"
      },
      "source": [
        "Use this dataset class to load the provided demonstrations. Furthermore, this dataset has functionality to add new samples to the dataset which you will need for implementing the DAgger algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9ihClXhjvOT",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class DemonstrationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_dir):\n",
        "        self.data_dir = data_dir\n",
        "        self.files = sorted(glob(f\"{data_dir}/*.npz\"))\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        data = np.load(self.files[idx])\n",
        "        state = data[\"state\"].astype(np.float32)\n",
        "        if state.ndim == 2:\n",
        "            state = np.expand_dims(state, axis=0)\n",
        "        action = data[\"action\"]\n",
        "        return state / 255.0, action.item()\n",
        "    \n",
        "    def append_one(self, state, action):\n",
        "        offset = len(self) + 1\n",
        "        filename = f\"{self.data_dir}/{offset:08}.npz\"\n",
        "        *remaining, w, h = state.shape\n",
        "        if np.prod(remaining) != 1:\n",
        "            raise ValueError(f\"unexpected state shape when adding to dataset: {state.shape}\")\n",
        "        if action.size != 1:\n",
        "            raise ValueError(f\"unexpected action shape when adding to dataset: {state.shape}\")\n",
        "        np.savez_compressed(\n",
        "            filename,\n",
        "            state=state.reshape(w, h),\n",
        "            action=action.reshape(()).astype(np.int32)\n",
        "        )\n",
        "        self.files.append(filename)\n",
        "\n",
        "    def append_more(self, states, actions):\n",
        "        for state, action in zip(states, actions):\n",
        "            self.append_one(state, actions)\n",
        "    \n",
        "    def append_iterable(self, states_and_actions):\n",
        "        for state, action in states_and_actions:\n",
        "            self.append_one(state, action)\n",
        "            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vViEbSRZj_4x"
      },
      "source": [
        "# Inspect data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dUd_3KWWDMh"
      },
      "source": [
        "It is always a good idea to take a look at the data when you start working with a new dataset. Feel free to investigate the dataset further on your own."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYljPrjekEEL",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Action Statistics\n",
        "dataset = DemonstrationDataset(\"train\")\n",
        "print(\"Number of samples: {}\".format(len(dataset)));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1itQJFxwkHYT",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Action mapping from gymnasium.farama.org\n",
        "action_mapping = {\n",
        "    0: \"do nothing\",\n",
        "    1: \"steer left\",\n",
        "    2: \"steer right\",\n",
        "    3: \"gas\",\n",
        "    4: \"brake\"\n",
        "}\n",
        "\n",
        "# Visualize random frames\n",
        "idx = np.random.randint(len(dataset))\n",
        "state, action = dataset[idx]\n",
        "# store a single frame as we need it later for exporting an ONNX model (it needs a sample of the input for the export)\n",
        "sample_state = torch.Tensor(state).unsqueeze(0).to(device)\n",
        "# Display the sample\n",
        "print(f\"Action: {action_mapping[action]}\")\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(state[0]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87zShnVElwv7",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# release memory\n",
        "del dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcUOi1VRmPTm"
      },
      "source": [
        "# Define Policy Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R4iC1PIWDMh"
      },
      "source": [
        "You need to design a neural network architecture that is capable of mapping a state to an action.\n",
        "The input is a single image with the following properties:\n",
        "- Resolution of 84x84 pixels\n",
        "- Grayscale (meaning a single channel as opposed to three channels of an RGB image)\n",
        "- The values of each pixel should be between 0 and 1\n",
        "\n",
        "The output of the network should be one unit per possible action, as our environment has 5 actions that results in 5 output units.\n",
        "Your network must implement the forward function in order to be compatible with the evaluation script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbVFFMoSmSpO",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from __future__ import annotations\n",
        "\n",
        "\n",
        "def set_submodule(module: torch.nn.Module, submodule_path: str, submodule: torch.nn.Module) -> None:\n",
        "    *parent_path, attr_name = submodule_path.split(\".\")\n",
        "    parent = module\n",
        "    for child in parent_path:\n",
        "        parent = getattr(parent, child)\n",
        "    setattr(parent, attr_name, submodule)\n",
        "\n",
        "\n",
        "class PolicyNetwork(nn.Module):\n",
        "    \"\"\"\n",
        "    Policy network is compatible with any CNN architecture as long as:\n",
        "    1) One of the conv layers determines how many channels it can process\n",
        "    2) One of the linear layers determines the number of output neurons\n",
        "    \n",
        "    This should be enough to support all standard architectures\n",
        "\n",
        "    >>> policy_nn = PolicyNetwork(\n",
        "    ...     actions=5,\n",
        "    ...     architecture=\"efficientnet_b0\",\n",
        "    ...     input_conv=\"features.0.0\",\n",
        "    ...     output_lin=\"classifier.1\",\n",
        "    ...     pretrained_weights=None, # \"IMAGENET1K_V1\"\n",
        "    ... )\n",
        "    >>> inputs = torch.rand(size=(16, 1, 64, 64))\n",
        "    >>> policy_nn(inputs).shape\n",
        "    torch.Size([16, 5])\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        actions: int | dict[int, str],\n",
        "        architecture: str,\n",
        "        input_conv: str,\n",
        "        output_lin: str,\n",
        "        pretrained_weights = None,\n",
        "        seed: int = 42,\n",
        "    ) -> None:\n",
        "        super(PolicyNetwork, self).__init__()\n",
        "        if isinstance(actions, int):\n",
        "            self.n_units_out = actions\n",
        "            self.actions = {i: f\"action_{i}\" for i in range(actions)}\n",
        "        else:\n",
        "            self.n_units_out = len(actions)\n",
        "            self.actions = actions\n",
        "        self.architecture = architecture\n",
        "        self.input_conv = input_conv\n",
        "        self.output_lin = output_lin\n",
        "        self.init(pretrained_weights, seed)\n",
        "\n",
        "    def init(self, pretrained_weights = None, seed: int = None) -> None:\n",
        "        \"\"\"\n",
        "        Initializes the model parameters, either randomly or with pretrained weights.\n",
        "        Patches the architecture to have desired input and output shape.\n",
        "        \"\"\"\n",
        "        if seed is not None:\n",
        "            torch.random.manual_seed(seed)\n",
        "        self.cnn = torchvision.models.get_model(self.architecture, weights=pretrained_weights)\n",
        "        self._patch_input_shape()\n",
        "        self._patch_output_shape()\n",
        "\n",
        "    def _patch_input_shape(self) -> None:\n",
        "        \"Make the architecture accept a single (grayscale) channel\"\n",
        "        old_in_conv = self.cnn.get_submodule(self.input_conv)\n",
        "        assert isinstance(old_in_conv, torch.nn.Conv2d)\n",
        "        new_in_conv = torch.nn.Conv2d(\n",
        "            in_channels = 1, \n",
        "            out_channels = old_in_conv.out_channels,\n",
        "            kernel_size = old_in_conv.kernel_size,\n",
        "            stride = old_in_conv.stride,\n",
        "            padding = old_in_conv.padding,\n",
        "            bias = old_in_conv.bias is not None,\n",
        "        )\n",
        "        set_submodule(self.cnn, self.input_conv, new_in_conv)\n",
        "\n",
        "    def _patch_output_shape(self) -> None:\n",
        "        \"Make the architecture output the correct shape\"\n",
        "        old_out_lin = self.cnn.get_submodule(self.output_lin)\n",
        "        assert isinstance(old_out_lin, torch.nn.Linear)\n",
        "        new_out_lin = torch.nn.Linear(\n",
        "            in_features = old_out_lin.in_features,\n",
        "            out_features = self.n_units_out,\n",
        "            bias = old_out_lin.bias is not None,\n",
        "        )\n",
        "        set_submodule(self.cnn, self.output_lin, new_out_lin)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # select only last channel if there are more\n",
        "        x = x[:, (-1,), :, :]\n",
        "        return self.cnn(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tv8P8s4rnOZM"
      },
      "source": [
        "# Train behavioral cloning policy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcfU-i6_WDMh"
      },
      "source": [
        "Now that you have a Dataset and a network you need to train your network.\n",
        "With behavioral cloning we want to imitate the behavior of the agent that produced the demonstration dataset as close as possible.\n",
        "This is basically supervised learning, where you want to minimize the loss of your network on the training and validation sets.\n",
        "\n",
        "Some tips as to what you need to implement:\n",
        "- choose the appropriate loss function (think on which kind of problem you are solving)\n",
        "- choose an optimizer and its hyper-parameters\n",
        "- optional: use a learning-rate scheduler\n",
        "- don't forget to evaluate your network on the validation set\n",
        "- store your model and training progress often so you don't loose progress if your program crashes\n",
        "\n",
        "In case you use the provided Logger:\n",
        "- `logger.log(\"training_loss\", <loss-value>)` to log a particular value\n",
        "- `logger.dump()` to write the current logs to a log file (e.g. after every episode)\n",
        "- `logger.log_dir`, `logger.param_file`, `logger.onnx_file`, `logger.video_dir` point to files or directories you can use to save files\n",
        "- you might want to specify your google drive folder as a logdir in order to automatically sync your results\n",
        "- if you log the metrics specified in the `plot_metrics` function you can use it to visualize your training progress (or take it as a template to plot your own metrics)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CropObservation(gym.ObservationWrapper):\n",
        "    def __init__(self, env, shape):\n",
        "        gym.ObservationWrapper.__init__(self, env)\n",
        "        self.shape = shape\n",
        "        obs_shape = self.shape + env.observation_space.shape[2:]\n",
        "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
        "\n",
        "    def observation(self, observation):\n",
        "        return observation[:self.shape[0], :self.shape[1]]\n",
        "\n",
        "    \n",
        "class RecordState(gym.Wrapper):\n",
        "    def __init__(self, env: gym.Env, enabled, reset_clean: bool = True):\n",
        "        gym.Wrapper.__init__(self, env)\n",
        "\n",
        "        assert env.render_mode is not None\n",
        "        self.frame_list = []\n",
        "        self.reset_clean = reset_clean\n",
        "        self.enabled = enabled\n",
        "\n",
        "    def step(self, action, **kwargs):\n",
        "        output = self.env.step(action, **kwargs)\n",
        "        if self.enabled:\n",
        "            self.frame_list.append(output[0])\n",
        "        return output\n",
        "\n",
        "    def reset(self, *args, **kwargs):\n",
        "        result = self.env.reset(*args, **kwargs)\n",
        "\n",
        "        if self.reset_clean:\n",
        "            self.frame_list = []\n",
        "        if self.enabled:\n",
        "            self.frame_list.append(result[0])\n",
        "\n",
        "        return result\n",
        "\n",
        "    def render(self):\n",
        "        frames = self.frame_list\n",
        "        self.frame_list = []\n",
        "        return frames\n",
        "    \n",
        "\n",
        "class Agent():\n",
        "    def __init__(self, model, device, supports_batch):\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.supports_batch = supports_batch\n",
        "\n",
        "    def select_action(self, state):\n",
        "        if not isinstance(state, torch.Tensor):\n",
        "            state = torch.tensor(state)\n",
        "\n",
        "        if not self.supports_batch and state.ndim == 4 and state.shape[0] > 1:\n",
        "            return np.stack([self.select_action(s) for s in state])\n",
        "\n",
        "        with torch.no_grad():\n",
        "            self.model.eval().to(self.device)\n",
        "            state = state.to(self.device) / 255.0 # rescale\n",
        "            if len(state.shape) == 3:\n",
        "              state = state.unsqueeze(0)\n",
        "            logits = self.model(state)\n",
        "            if type(logits) is tuple:\n",
        "                logits = logits[0]\n",
        "            probs = Categorical(logits=logits)\n",
        "            selected = probs.sample().cpu().numpy()\n",
        "            if selected.size == 1:\n",
        "                return selected.item()\n",
        "            return selected\n",
        "        \n",
        "            \n",
        "def make_env(seed, capture_video=True, enabled_record_state=False):\n",
        "    env = gym.make(\"CarRacing-v2\", render_mode=\"rgb_array\", continuous=False)\n",
        "    env = gym.wrappers.RecordEpisodeStatistics(env)\n",
        "    if capture_video:\n",
        "        env = gym.wrappers.RecordVideo(env, logger.video_dir)\n",
        "            \n",
        "    env = CropObservation(env, (84, 96))\n",
        "    env = gym.wrappers.ResizeObservation(env, (84, 84))\n",
        "    env = gym.wrappers.GrayScaleObservation(env)    \n",
        "    env = RecordState(env, reset_clean=True, enabled=enabled_record_state)\n",
        "    env = gym.wrappers.FrameStack(env, 4)\n",
        "    env.reset(seed=seed)\n",
        "    env.action_space.seed(seed)\n",
        "    env.observation_space.seed(seed)\n",
        "    return env\n",
        "\n",
        "\n",
        "def run_episode(agent, show_progress=True, capture_video=True, seed=None):\n",
        "    env = make_env(seed=seed, capture_video=capture_video)\n",
        "    state, _ = env.reset()\n",
        "    score = 0\n",
        "    done = False\n",
        "    if show_progress:\n",
        "        progress = tqdm(desc=\"Score: 0\")\n",
        "        \n",
        "    while not done:\n",
        "        action = agent.select_action(state[-1][np.newaxis, ...])\n",
        "        state, reward, terminated, truncated, _ = env.step(action)\n",
        "        score += reward\n",
        "        done = terminated or truncated\n",
        "        if show_progress:\n",
        "            progress.update()\n",
        "            progress.set_description(\"Score: {:.2f}\".format(score))       \n",
        "    env.close()\n",
        "    \n",
        "    if show_progress:\n",
        "        progress.close()    \n",
        "    if capture_video:\n",
        "        show_video_from_folder(logger.video_dir)\n",
        "    \n",
        "    return score"
      ],
      "metadata": {
        "id": "zUVrnVln0bvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the google drive mount here if you want to store logs and weights there (and set it up earlier)\n",
        "logger = Logger(\"logdir_dagger\")\n",
        "print(\"Saving state to {}\".format(logger.basepath))\n"
      ],
      "metadata": {
        "id": "2xzK4103CBJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install \\\n",
        "  lovely-tensors==0.1.14 \\\n",
        "  lovely-numpy==0.2.8 \\\n",
        "  lightning==2.0.1 \\\n",
        "1> /dev/null"
      ],
      "metadata": {
        "id": "voP1KVO5478w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lovely_tensors\n",
        "import lovely_numpy\n",
        "\n",
        "def lovely(x):\n",
        "    \"summarizes important tensor properties\"\n",
        "    if isinstance(x, np.ndarray):\n",
        "        return lovely_numpy.lovely(x)\n",
        "    return lovely_tensors.lovely(x)"
      ],
      "metadata": {
        "id": "-UJGai54p9LL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Iterable\n",
        "\n",
        "def measure_scores_parallel(agent: Agent, num_episodes: int, limit_steps: int = None, return_unfinished: bool = False) -> Iterable[float]:\n",
        "    env = gym.vector.AsyncVectorEnv([\n",
        "        lambda: make_env(seed=None, capture_video=False)\n",
        "        for _ in range(num_episodes)\n",
        "    ])\n",
        "    \n",
        "    if limit_steps is None:\n",
        "        limit_steps = env.get_attr(\"spec\")[0].max_episode_steps\n",
        "    if limit_steps is None:\n",
        "        raise ValueError(\"limit_steps must not be None\")\n",
        "\n",
        "    state, _ = env.reset()\n",
        "    score = np.zeros(num_episodes)\n",
        "    done = np.zeros(num_episodes, dtype=bool)\n",
        "\n",
        "    for i in tqdm(range(limit_steps), \"Measuring score - step\"):\n",
        "        action = agent.select_action(state)\n",
        "        state, reward, terminated, truncated, _ = env.step(action)\n",
        "        # don't update score of episodes that ended already\n",
        "        # vector env resets them automatically and starts over\n",
        "        score[~done] += reward[~done]\n",
        "        curr_ended = terminated | truncated\n",
        "        done |= curr_ended\n",
        "        for idx in curr_ended.nonzero()[0]:\n",
        "            yield score[idx].item()\n",
        "\n",
        "        if done.all():\n",
        "            break\n",
        "      \n",
        "    env.close()\n",
        "\n",
        "    if return_unfinished:\n",
        "        yield from score[~done].tolist()\n"
      ],
      "metadata": {
        "id": "UGqDexzK9vJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightning\n",
        "\n",
        "class MetricsHistoryKeeper(lightning.Callback):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.history = []\n",
        "\n",
        "    def on_validation_epoch_end(self, trainer, pl_module):\n",
        "        metrics = {}\n",
        "        for key, value in trainer.callback_metrics.items():\n",
        "            if isinstance(value, torch.Tensor):\n",
        "                value = value.cpu().numpy()\n",
        "            if isinstance(value, np.ndarray) and value.size == 1:\n",
        "                value = value.item()\n",
        "            metrics[key] = value\n",
        "        self.history.append(metrics)"
      ],
      "metadata": {
        "id": "TwesaQbOv-0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pM7ylckLnRnP",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import wandb\n",
        "from typing import Any\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Datasets\n",
        "train_set = DemonstrationDataset(\"train\")\n",
        "val_set = DemonstrationDataset(\"val\")\n",
        "\n",
        "# Specify the google drive mount here if you want to store logs and weights there (and set it up earlier)\n",
        "# You can also choose to use a different logging framework such as tensorboard (not recommended on Colab) or Weights & Biases (highly recommended)\n",
        "#logger = Logger(\"logdir\")\n",
        "#print(\"Saving state to {}\".format(logger.basepath))\n",
        "\n",
        "\n",
        "######################\n",
        "### YOUR CODE HERE ###\n",
        "######################\n",
        "\n",
        "\n",
        "import time\n",
        "import copy\n",
        "import pathlib\n",
        "from typing import Tuple, Dict\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "class LightningPolicyNetwork(lightning.LightningModule):\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        model_config: dict[str, Any],\n",
        "        num_val_episodes: int,\n",
        "        limit_val_steps: int | None,\n",
        "        label_smoothing: float,\n",
        "        dummy_score_during_sanity_check: float | None,\n",
        "    ) -> None:\n",
        "\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.model_config = model_config\n",
        "        self.num_val_episodes = num_val_episodes\n",
        "        self.limit_val_steps = limit_val_steps\n",
        "        self.dummy_score_during_sanity_check = dummy_score_during_sanity_check\n",
        "\n",
        "        self.model = PolicyNetwork(**model_config, pretrained_weights=None)\n",
        "        self.loss_fn = torch.nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "        self.loss_name = \"cross_entropy_loss\"\n",
        "\n",
        "        self.simulation_test_kwargs = None\n",
        "\n",
        "    def configure_optimizers(self) -> torch.optim.Optimizer:\n",
        "        return torch.optim.Adam(self.parameters(), lr=1e-4)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.model(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def _entropy(logits: torch.Tensor) -> torch.Tensor:\n",
        "        return -(logits.softmax(dim=-1) * logits.log_softmax(dim=-1)).sum(dim=-1).mean()\n",
        "\n",
        "    def training_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx) -> torch.Tensor:\n",
        "        state, action = batch\n",
        "        logits = self(state)\n",
        "        loss = self.loss_fn(logits, action)\n",
        "        self.log_dict({\n",
        "            \"train/\" + self.loss_name: loss,\n",
        "            \"train/entropy\": self._entropy(logits)\n",
        "        })\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx) -> torch.Tensor:\n",
        "        state, action = batch\n",
        "        logits: torch.Tensor = self(state)\n",
        "        loss = self.loss_fn(logits, action)\n",
        "        accuracy = (logits.argmax(dim=-1) == action).float().mean()\n",
        "        self.log_dict({\n",
        "            \"valid/\" + self.loss_name: loss,\n",
        "            \"valid/entropy\": self._entropy(logits),\n",
        "            \"valid/accuracy\": accuracy,\n",
        "        })\n",
        "        return loss\n",
        "\n",
        "    def test_in_simulation(self, num_episodes: int, limit_steps: int, return_unfinished: bool, log: bool, device = None) -> np.ndarray:\n",
        "        if device is None:\n",
        "            device = self.device\n",
        "        agent = Agent(self.model, device, supports_batch=True)\n",
        "        scores = measure_scores_parallel(agent, num_episodes, limit_steps, return_unfinished)\n",
        "        scores = np.array(list(scores))\n",
        "        if log:\n",
        "            self.log_simulation_metrics(scores, limit_steps, return_unfinished)\n",
        "        return scores\n",
        "\n",
        "    def simulation_metrics(self, scores: np.ndarray) -> dict[str, Any]:\n",
        "        basic = {\n",
        "            \"num_episodes\": float(len(scores)),\n",
        "            \"score_avg\": float(scores.mean()),\n",
        "            \"score_std\": float(scores.std()),\n",
        "            \"score_min\": float(scores.min()),\n",
        "            \"score_max\": float(scores.max())\n",
        "        }\n",
        "        percentiles = {\n",
        "            f\"score_percentile_{p}\": pd.Series(scores).quantile(p / 100)\n",
        "            for p in [20, 35, 50, 65, 80]\n",
        "        }\n",
        "        return {**basic, **percentiles}\n",
        "\n",
        "    def log_simulation_metrics(self, scores: np.ndarray, limit_steps: int, return_unfinished: bool) -> dict[str, Any]:\n",
        "        prefix = \"simulation\" if limit_steps is None else \"simulation_limited\"\n",
        "\n",
        "        for logger in self.loggers:\n",
        "            if not isinstance(logger, lightning.pytorch.loggers.WandbLogger):\n",
        "                continue\n",
        "            logger.log_metrics({f\"{prefix}/score\": wandb.Histogram(scores)})\n",
        "\n",
        "        self.log_dict({\n",
        "            f\"{prefix}/{name}\": value\n",
        "            for name, value in self.simulation_metrics(scores).items()\n",
        "        })\n",
        "\n",
        "        self.log_dict({\n",
        "            f\"{prefix}/limit_steps\": -1.0 if limit_steps is None else float(limit_steps),\n",
        "            f\"{prefix}/return_unfinished\": 1.0 if return_unfinished else 0.0,\n",
        "            f\"{prefix}/was_sanity_check\": 1.0 if self.trainer.sanity_checking else 0.0,\n",
        "        })\n",
        "\n",
        "    def on_validation_epoch_end(self) -> None:\n",
        "        if self.trainer.sanity_checking:\n",
        "            limit_steps = 10\n",
        "        else:\n",
        "            limit_steps = self.limit_val_steps\n",
        "\n",
        "        return_unfinished = True\n",
        "        scores = self.test_in_simulation(self.num_val_episodes, limit_steps, return_unfinished, log=False)\n",
        "\n",
        "        if self.trainer.sanity_checking and self.dummy_score_during_sanity_check is not None:\n",
        "            scores = np.full(self.num_val_episodes, self.dummy_score_during_sanity_check, dtype=float)\n",
        "            limit_steps = 0\n",
        "            return_unfinished = False\n",
        "\n",
        "        self.log_simulation_metrics(scores, limit_steps, return_unfinished)\n",
        "\n",
        "    def prepare_testing(self, **kwargs: Any) -> None:\n",
        "        self.simulation_test_kwargs = kwargs\n",
        "\n",
        "    def test_step(self, *args: Any, **kwargs: Any) -> None:\n",
        "        print(\"test step: IGNORING input\")\n",
        "    \n",
        "    def on_test_epoch_end(self):\n",
        "         return self.test_in_simulation(**self.simulation_test_kwargs, log=True)\n",
        "\n",
        "\n",
        "class MyDataModule(lightning.LightningDataModule):\n",
        "    def __init__(self, train_set: DemonstrationDataset, val_set: DemonstrationDataset, batch_size: int, num_workers: int, prefetch_factor: int, pin_memory: int):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.train_set = train_set\n",
        "        self.val_set = val_set\n",
        "        self.num_workers = num_workers\n",
        "        self.prefetch_factor = prefetch_factor\n",
        "        self.pin_memory = pin_memory\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        print(f\"RELOADING TRAIN DATALOADER. dataset size = {len(self.train_set)}\")\n",
        "        return torch.utils.data.DataLoader(\n",
        "            self.train_set,\n",
        "            shuffle=True,\n",
        "            batch_size=self.batch_size,\n",
        "            num_workers=self.num_workers,\n",
        "            prefetch_factor=self.prefetch_factor,\n",
        "            pin_memory=self.pin_memory,\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(\n",
        "            self.val_set,\n",
        "            shuffle=False,\n",
        "            batch_size=self.batch_size,\n",
        "            num_workers=self.num_workers,\n",
        "            prefetch_factor=self.prefetch_factor,\n",
        "            pin_memory=self.pin_memory,\n",
        "        )\n",
        "\n",
        "\n",
        "wandb_logger = lightning.pytorch.loggers.WandbLogger(\n",
        "    project=\"jku-deep-rl_imitation-learning\",\n",
        "    save_dir=\"wandb\",\n",
        ")\n",
        "\n",
        "checkpointing = lightning.pytorch.callbacks.ModelCheckpoint(\n",
        "    monitor=\"simulation_limited/score_avg\",\n",
        "    mode=\"max\",\n",
        "    save_last=True,\n",
        "    save_top_k=5,\n",
        "    dirpath=f\"checkpoints/{wandb_logger.experiment.name}/\",\n",
        "    filename=\"step={step}_score-avg={simulation/score_avg:.2f}_score-percentile-30={simulation/score_percentile_30}\",\n",
        "    auto_insert_metric_name=False,\n",
        ")\n",
        "\n",
        "metrics_history_keeper = MetricsHistoryKeeper()\n",
        "\n",
        "model_config = dict(\n",
        "    actions=action_mapping,\n",
        "    architecture=\"efficientnet_b0\",\n",
        "    input_conv=\"features.0.0\",\n",
        "    output_lin=\"classifier.1\",\n",
        ")\n",
        "\n",
        "lightning_model = LightningPolicyNetwork(\n",
        "    model_config,\n",
        "    num_val_episodes=8,\n",
        "    limit_val_steps=500,\n",
        "    label_smoothing=0.01,\n",
        "    dummy_score_during_sanity_check=0,\n",
        ")\n",
        "\n",
        "wandb_logger.experiment.config.update({\n",
        "    \"dagger_enabled\": False,\n",
        "})\n",
        "\n",
        "datamodule = MyDataModule(\n",
        "    train_set=train_set,\n",
        "    val_set=val_set,\n",
        "    num_workers=4,\n",
        "    batch_size=128,\n",
        "    prefetch_factor=8,\n",
        "    pin_memory=True,\n",
        ")\n",
        "\n",
        "num_batches = len(train_set) / datamodule.batch_size\n",
        "\n",
        "trainer = lightning.Trainer(\n",
        "    logger=wandb_logger,\n",
        "    val_check_interval=int(0.8 * num_batches),\n",
        "    max_epochs=3,\n",
        "    precision=\"16-mixed\",\n",
        "    accelerator=\"auto\",\n",
        "    callbacks=[\n",
        "        checkpointing,\n",
        "        metrics_history_keeper,\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(\n",
        "    lightning_model,\n",
        "    datamodule\n",
        ")"
      ],
      "metadata": {
        "id": "6-odJodYNrot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0n4lK97nwYee"
      },
      "outputs": [],
      "source": [
        "lightning_model = LightningPolicyNetwork.load_from_checkpoint(checkpointing.best_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUlXn25HwYef"
      },
      "outputs": [],
      "source": [
        "# If you want to export your model as an ONNX file use the following code as template\n",
        "# If you use the provided logger you can use this directly\n",
        "save_as_onnx(\n",
        "    lightning_model.model.to(\"cpu\"),\n",
        "    sample_state.to(\"cpu\"),\n",
        "    pathlib.Path(checkpointing.best_model_path).with_suffix(\".onnx\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PelO4qdwuwK"
      },
      "source": [
        "# Evaluate the agent in the real environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVrASW_Hy1lo"
      },
      "source": [
        "### Environment and Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTFAzdfiaYmu"
      },
      "source": [
        "We provide some wrappers you need in order to get the same states from the environment as in the demonstration dataset.\n",
        "Additionally the `RecordState` wrapper should be very helpful in collecting new samples for the DAgger algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkjTFDi3y72N"
      },
      "source": [
        "## Evaluate behavioral cloning agent"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "history = pd.DataFrame(metrics_history_keeper.history)\n",
        "history"
      ],
      "metadata": {
        "id": "0m0q5DUFdrij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_point = history[\"simulation_limited/score_avg\"].idxmax()\n",
        "history.loc[best_point]"
      ],
      "metadata": {
        "id": "9vJjOPvReV53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0JaMOvxzBio"
      },
      "source": [
        "Let's see how the agent is doing in the real environment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lightning_model.prepare_testing(num_episodes=2, limit_steps=None, return_unfinished=False)\n",
        "metrics = trainer.test(lightning_model, torch.utils.data.DataLoader([0]))[0]"
      ],
      "metadata": {
        "id": "9gharoExN1us"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrqzgG-bzXws",
        "tags": []
      },
      "outputs": [],
      "source": [
        "agent = Agent(lightning_model.model, device, supports_batch=True)\n",
        "score = run_episode(agent, show_progress=True, capture_video=True);\n",
        "print(f\"Score: {score:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb_logger.experiment.finish()"
      ],
      "metadata": {
        "id": "zcgPjv3kzk0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmDAORUGhJQD"
      },
      "source": [
        "# DAGGER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8Y8WBIkXvlP"
      },
      "source": [
        "Now we can implement DAgger, you have downloaded a relatively well trained model you can use as an expert for this purpose.\n",
        "\n",
        "Load expert model that is provided as ONNX file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqFaY_8ZprUw"
      },
      "source": [
        "## Load the expert"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load expert\n",
        "expert_model = ConvertModel(onnx.load(\"expert.onnx\"))\n",
        "\n",
        "# Freeze expert weights\n",
        "for p in expert_model.parameters():\n",
        "    p.requires_grad_(False)\n",
        "    \n",
        "expert_agent = Agent(expert_model, device, supports_batch=False)"
      ],
      "metadata": {
        "id": "V2unzUohQfb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmYXqfOZX0Yr"
      },
      "source": [
        "Next, you have to implement the DAgger algorithm (see slides for details). This function implements the core idea of DAgger:\n",
        "\n",
        "\n",
        "1. Choose the policy with probability beta\n",
        "2. Sample T-step trajectories using this policy\n",
        "3. Label the gathered states with the expert\n",
        "\n",
        "The aggregation and training part are already implemented."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "def collect_data_parallel(\n",
        "    train_agent: Agent,\n",
        "    expert_agent: Agent,\n",
        "    num_parallel_envs: int,\n",
        "    num_steps: int,\n",
        "    follow_expert: bool,\n",
        "    single_frame: bool = True,\n",
        ") -> Iterable[tuple[np.ndarray, np.ndarray]]:\n",
        "    \"\"\"\n",
        "    Yields:\n",
        "      state: np.ndarray of shape observation_shape\n",
        "      action: np.ndarray scalar\n",
        "    in total it yields (num_parallel_envs * num_steps) times\n",
        "    \"\"\"\n",
        "\n",
        "    env = gym.vector.AsyncVectorEnv([\n",
        "        lambda: make_env(seed=None, capture_video=False)\n",
        "        for _ in range(num_parallel_envs)\n",
        "    ])\n",
        "    \n",
        "    if num_steps is None:\n",
        "        num_steps = env.get_attr(\"spec\")[0].max_episode_steps\n",
        "    if num_steps is None:\n",
        "        raise ValueError(\"num_steps must not be None\")\n",
        "\n",
        "    states, _ = env.reset()\n",
        "    for i in tqdm(range(num_steps), desc=\"Collecting data - step\"):\n",
        "        expert_actions = expert_agent.select_action(states)\n",
        "        if follow_expert:\n",
        "            actions = expert_actions\n",
        "        else:\n",
        "            actions = train_agent.select_action(states)\n",
        "        states, rewards, terminateds, truncateds, _ = env.step(actions)\n",
        "        if single_frame:\n",
        "            states_out = states[:, (-1,), :, :]\n",
        "        else:\n",
        "            states_out = states\n",
        "        yield from zip(states_out, expert_actions)\n",
        "\n",
        "    env.close()\n"
      ],
      "metadata": {
        "id": "MeiT-khdQdcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jso18L4z2Gio",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class DaggerDataCollectionCallback(lightning.Callback):\n",
        "    def __init__(\n",
        "        self,\n",
        "        train_set: DemonstrationDataset,\n",
        "        collect_every_nth_epoch: int,\n",
        "        expert_agent: Agent,\n",
        "        device: torch.device,\n",
        "        num_parallel_envs: int,\n",
        "        num_steps_follow_train: int,\n",
        "        num_steps_follow_expert: int\n",
        "    ) -> None:\n",
        "        self.train_set = train_set\n",
        "        self.collect_every_nth_epoch = collect_every_nth_epoch\n",
        "        self.expert_agent = expert_agent\n",
        "        self.device = device\n",
        "        self.num_parallel_envs = num_parallel_envs\n",
        "        self.num_steps_follow_train = num_steps_follow_train\n",
        "        self.num_steps_follow_expert = num_steps_follow_expert\n",
        "        self.duration_wall_time = 0\n",
        "        self.duration_process_time = 0\n",
        "\n",
        "    def setup(self, trainer: lightning.Trainer, lightning_model: lightning.LightningModule, stage: str) -> None:\n",
        "        if trainer.reload_dataloaders_every_n_epochs == 0:\n",
        "            raise ValueError(\n",
        "                f\"{self.__class__.__name__} requires\"\n",
        "                \"`trainer.reload_dataloaders_every_n_epochs` to be a positive integer, ideally 1.\"\n",
        "            )\n",
        "\n",
        "    def on_train_epoch_start(self, trainer: lightning.Trainer, lightning_model: LightningPolicyNetwork) -> None:\n",
        "        lightning_model.log_dict({\n",
        "            \"dagger/dataset_size\": float(len(self.train_set)),\n",
        "            \"dagger/collect_data_wall_seconds\": self.duration_wall_time,\n",
        "            \"dagger/collect_data_process_seconds\": self.duration_process_time,\n",
        "            \"dagger/num_steps_follow_train\": float(self.num_steps_follow_train),\n",
        "            \"dagger/num_steps_follow_expert\": float(self.num_steps_follow_expert),\n",
        "            \"dagger/num_parallel_envs\": float(self.num_parallel_envs),\n",
        "        })\n",
        "\n",
        "    def on_train_epoch_end(self, trainer: lightning.Trainer, lightning_model: LightningPolicyNetwork) -> None:\n",
        "        if self.collect_every_nth_epoch is None:\n",
        "            return\n",
        "        if trainer.current_epoch % self.collect_every_nth_epoch != 0:\n",
        "            return\n",
        "        if trainer.current_epoch == trainer.max_epochs - 1:\n",
        "            return\n",
        "\n",
        "        train_agent = Agent(lightning_model.model, self.device, supports_batch=True)\n",
        "        start_wall_time = time.time()\n",
        "        start_process_time = time.process_time()\n",
        "\n",
        "        self.train_set.append_iterable(\n",
        "            collect_data_parallel(\n",
        "                train_agent,\n",
        "                self.expert_agent,\n",
        "                self.num_parallel_envs,\n",
        "                self.num_steps_follow_expert,\n",
        "                follow_expert=True,\n",
        "            )\n",
        "        )\n",
        "\n",
        "        self.train_set.append_iterable(\n",
        "            collect_data_parallel(\n",
        "                train_agent,\n",
        "                self.expert_agent,\n",
        "                self.num_parallel_envs,\n",
        "                self.num_steps_follow_train,\n",
        "                follow_expert=False,\n",
        "            )\n",
        "        )\n",
        "\n",
        "        self.duration_wall_time = time.time() - start_wall_time\n",
        "        self.duration_process_time = time.process_time() - start_process_time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svRD7bwpWDMj"
      },
      "source": [
        "Put everything together now. \n",
        "1. Create new samples using the DAgger algorithm\n",
        "2. Continue training your agent\n",
        "3. Export your fully trained agent as an ONNX file"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "wandb_logger = lightning.pytorch.loggers.WandbLogger(\n",
        "    project=\"jku-deep-rl_imitation-learning\",\n",
        "    save_dir=\"wandb\",\n",
        ")\n",
        "\n",
        "checkpointing = lightning.pytorch.callbacks.ModelCheckpoint(\n",
        "    monitor=\"simulation_limited/score_avg\",\n",
        "    mode=\"max\",\n",
        "    save_last=True,\n",
        "    save_top_k=5,\n",
        "    dirpath=f\"checkpoints/{wandb_logger.experiment.name}/\",\n",
        "    filename=\"step={step}_score-avg={simulation/score_avg:.2f}_score-percentile-30={simulation/score_percentile_30}\",\n",
        "    auto_insert_metric_name=False,\n",
        ")\n",
        "\n",
        "metrics_history_keeper = MetricsHistoryKeeper()\n",
        "\n",
        "model_config = dict(\n",
        "    actions=action_mapping,\n",
        "    architecture=\"efficientnet_b0\",\n",
        "    input_conv=\"features.0.0\",\n",
        "    output_lin=\"classifier.1\",\n",
        ")\n",
        "\n",
        "lightning_model = LightningPolicyNetwork(\n",
        "    model_config,\n",
        "    num_val_episodes=8,\n",
        "    limit_val_steps=500,\n",
        "    label_smoothing=0.01,\n",
        "    dummy_score_during_sanity_check=0,\n",
        ")\n",
        "\n",
        "datamodule = MyDataModule(\n",
        "    train_set=train_set,\n",
        "    val_set=val_set,\n",
        "    num_workers=4,\n",
        "    batch_size=128,\n",
        "    prefetch_factor=8,\n",
        "    pin_memory=True,\n",
        ")\n",
        "\n",
        "dagger_data_collection_callback = DaggerDataCollectionCallback(\n",
        "    train_set=train_set,\n",
        "    collect_every_nth_epoch=1,\n",
        "    expert_agent=expert_agent,\n",
        "    num_parallel_envs=4,\n",
        "    num_steps_follow_train=1000,\n",
        "    num_steps_follow_expert=3000,\n",
        ")\n",
        "\n",
        "wandb_logger.experiment.config.update({\n",
        "    \"dagger_enabled\": True,\n",
        "})\n",
        "\n",
        "num_batches = len(train_set) / datamodule.batch_size\n",
        "\n",
        "trainer = lightning.Trainer(\n",
        "    logger=wandb_logger,\n",
        "    val_check_interval=num_batches,\n",
        "    reload_dataloaders_every_n_epochs=1,\n",
        "    max_epochs=3,\n",
        "    precision=\"16-mixed\",\n",
        "    accelerator=\"auto\",\n",
        "    callbacks=[\n",
        "        checkpointing,\n",
        "        metrics_history_keeper,\n",
        "        dagger_data_collection_callback, # CRUCIAL !!!\n",
        "    ],\n",
        ")\n"
      ],
      "metadata": {
        "id": "DE6SIzclRE5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXlZWzRsZ2dJ",
        "tags": []
      },
      "outputs": [],
      "source": [
        "save_as_onnx(\n",
        "    lightning_model.model.to(\"cpu\"),\n",
        "    sample_state.to(\"cpu\"),\n",
        "    logger.onnx_file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iOeC98o9Pw-",
        "tags": []
      },
      "outputs": [],
      "source": [
        "agent = Agent(lightning_model.model, device, supports_batch=True)\n",
        "scores = measure_scores_parallel(agent, num_episodes=32)\n",
        "scores = np.array(list(scores))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores.mean(), scores.std()"
      ],
      "metadata": {
        "id": "SnZpCLrGpu8A"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
